{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Yet-Another-EfficientDet-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import albumentations as A\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from efficientdet.mydataset import CocoDataset, CocoDatasetForAlbumentations\n",
    "from efficientdet.mydataset import Resizer, Normalizer, Augmenter, collater\n",
    "from efficientdet.loss import FocalLoss\n",
    "from utils.sync_batchnorm import patch_replication_callback\n",
    "from utils.utils import replace_w_sync_bn, CustomDataParallel, get_last_weights, init_weights, boolean_string\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, project_file):\n",
    "        with open(project_file) as f:\n",
    "            self.params = yaml.safe_load(f)\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return self.params.get(item, None)\n",
    "\n",
    "# print current path\n",
    "print(os.getcwd())\n",
    "\n",
    "params = Params(f'./projects/fashion.yml')\n",
    "training_params = {\n",
    "    'batch_size': 1,\n",
    "    'shuffle': False,\n",
    "    'drop_last': True,\n",
    "    'collate_fn': collater,\n",
    "    'num_workers': 1\n",
    "}\n",
    "# make option with dot dict\n",
    "opt = {\n",
    "    'compound_coef': 7,\n",
    "    'num_workers': 1,\n",
    "    'data_path': '../../',\n",
    "    'compound_coef': 0,\n",
    "}\n",
    "opt = argparse.Namespace(**opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "def random_box_color():\n",
    "    # random hsv color: saturation, brightness is always maximum\n",
    "    hsv_color = np.array([np.random.randint(0, 179), 255, 200], dtype=np.uint8)\n",
    "\n",
    "    # convert (h, s, v) to (r, g, b) color space\n",
    "    rgb_color = cv2.cvtColor(np.array([[hsv_color]], dtype=np.uint8), cv2.COLOR_HSV2RGB)[0][0]\n",
    "\n",
    "    return rgb_color.tolist()\n",
    "\n",
    "print(random_box_color())\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "   \n",
    "    # print(img)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name, scores):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id, score in zip(bboxes, category_ids, scores):\n",
    "        if score < 0.3:\n",
    "            continue\n",
    "        if category_id not in category_id_to_name:\n",
    "            continue\n",
    "        class_name = category_id_to_name[category_id]\n",
    "        img = visualize_bbox(img, bbox, class_name, random_box_color())\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
    "\n",
    "input_size = input_sizes[opt.compound_coef]\n",
    "\n",
    "\n",
    "def getLoader():\n",
    "    training_transform = A.Compose([\n",
    "        A.Normalize(),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        A.LongestMaxSize(max_size=input_sizes[opt.compound_coef]),\n",
    "        # A.BBoxSafeRandomCrop(height=input_size, width=input_size, p=1.0),\n",
    "        A.PadIfNeeded(min_height=input_size, min_width=input_size, position=A.PadIfNeeded.PositionType.TOP_LEFT, border_mode=cv2.BORDER_CONSTANT, value=[0, 0, 0], p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='coco', label_fields=['category_id']))\n",
    "\n",
    "    training_set = CocoDatasetForAlbumentations(\n",
    "        root_dir=os.path.join(opt.data_path, params.project_name),\n",
    "        set=params.train_set,\n",
    "        transform=training_transform\n",
    "    )\n",
    "\n",
    "    return DataLoader(training_set, **training_params)\n",
    "\n",
    "def getOriginalLoader():\n",
    "\n",
    "    training_transform = transforms.Compose([\n",
    "        Normalizer(mean=params.mean, std=params.std),\n",
    "        Resizer(input_sizes[opt.compound_coef])\n",
    "    ])\n",
    "    training_set = CocoDataset(\n",
    "        root_dir=os.path.join(opt.data_path, params.project_name),\n",
    "        set=params.train_set,\n",
    "        transform=training_transform\n",
    "    )\n",
    "\n",
    "    return DataLoader(training_set, **training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter, (data, odata) in enumerate(zip(getLoader(), getOriginalLoader())):\n",
    "    if iter == 3:\n",
    "        break\n",
    "\n",
    "    # print(iter)\n",
    "    # print(data)\n",
    "    img, annot = data['img'], data['annot']\n",
    "    img = img\n",
    "    img = img.permute(0, 2, 3, 1).numpy()\n",
    "    rois = annot[:, :, :4].numpy()\n",
    "    class_ids = annot[:, :, 4].numpy()\n",
    "\n",
    "    oimg, oannot = odata['img'], odata['annot']\n",
    "    oimg = oimg.permute(0, 2, 3, 1).numpy()\n",
    "    oroiss = oannot[:, :, :4].numpy()\n",
    "    oclass_ids = oannot[:, :, 4].numpy()\n",
    "\n",
    "    print('img', img[0, 0, :3, :3])\n",
    "    print('ori', oimg[0, 0, :3, :3])\n",
    "\n",
    "    category_id_to_name = {v: k for v, k in enumerate(params.obj_list)}\n",
    "    visualize(img[0], rois[0], class_ids[0], category_id_to_name, np.ones(len(rois[0])))\n",
    "    visualize(oimg[0], oroiss[0], oclass_ids[0], category_id_to_name, np.ones(len(oroiss[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
